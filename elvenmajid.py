import streamlit as st
import json
import arabic_reshaper
from bidi.algorithm import get_display
import networkx as nx
import matplotlib.pyplot as plt
from PIL import Image
import matplotlib.font_manager as fm
import re
from collections import Counter
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import speech_recognition as sr

# ØªØ­Ù…ÙŠÙ„ Ø®Ø· ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
arabic_font = fm.FontProperties(fname="arial.ttf")


def reshape_arabic_text(text):
    """Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø±Ø³Ù…"""
    reshaped_text = arabic_reshaper.reshape(text)
    return get_display(reshaped_text)


def load_knowledge_base():
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ù…Ù„Ù JSON"""
    file_name = "translated_diseases_v2.json"
    try:
        with open(file_name, "r", encoding="utf-8") as file:
            data = json.load(file)
            return data.get("symptoms", {})
    except FileNotFoundError:
        st.error("âš ï¸ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return {}


def preprocess_text(text):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„"""
    text = re.sub(r'[^\w\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ©
    text = re.sub(r'Ø¥', "Ø§", text)  # ØªØµØ­ÙŠØ­ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø±ÙˆÙ
    text = re.sub(r'Ø£', "Ø§", text)
    return text.strip().split()


def build_semantic_network(knowledge_base):
    """Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø¯Ù„Ø§Ù„ÙŠØ© Ù„Ù„Ø£Ù…Ø±Ø§Ø¶ ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ø¶"""
    network = nx.DiGraph()
    for disease, details in knowledge_base.items():
        network.add_node(disease, type="disease")
        for symptom in details.get("Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶", []):
            network.add_node(symptom, type="symptom")
            network.add_edge(disease, symptom, relation="has_symptom")
    return network


def diagnose_disease(input_text, knowledge_base, semantic_network):
    """ØªØ´Ø®ÙŠØµ Ø§Ù„Ù…Ø±Ø¶ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©"""
    input_symptoms = preprocess_text(input_text)
    disease_scores = Counter()

    for disease in knowledge_base:
        matched_symptoms = sum(1 for symptom in input_symptoms if symptom in knowledge_base[disease]["Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"])
        if matched_symptoms:
            disease_scores[disease] = matched_symptoms

    if disease_scores:
        best_match = disease_scores.most_common(1)[0][0]
        details = knowledge_base.get(best_match, {})
        return best_match, details
    return None, None


def visualize_network(input_text, semantic_network):
    """Ø±Ø³Ù… Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©"""
    input_symptoms = preprocess_text(input_text)
    sub_network = nx.DiGraph()

    for symptom in input_symptoms:
        if symptom in semantic_network.nodes:
            sub_network.add_node(symptom, type="symptom")
            for disease in semantic_network.predecessors(symptom):
                sub_network.add_node(disease, type="disease")
                sub_network.add_edge(disease, symptom, relation="has_symptom")

    if sub_network.nodes:
        plt.figure(figsize=(10, 8))
        pos = nx.spring_layout(sub_network, seed=42)
        node_colors = ["lightblue" if sub_network.nodes[node].get("type") == "disease" else "lightcoral" for node in
                       sub_network.nodes]
        nx.draw(sub_network, pos, with_labels=True, node_color=node_colors, node_size=1500, font_size=10,
                font_family="Arial")
        st.pyplot(plt)
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´Ø¨ÙƒØ© Ø¯Ù„Ø§Ù„ÙŠØ© Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©.")


def recognize_speech():
    """Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… sounddevice"""
    fs = 16000  # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø© (16 kHz)
    duration = 5  # Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
    st.info("ğŸ¤ ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†...")

    try:
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float64')
        sd.wait()  # Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        st.success("âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­!")

        # Ø­ÙØ¸ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙƒÙ…Ù„Ù Ù…Ø¤Ù‚Øª
        write("temp_recording.wav", fs, recording)

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Speech Recognition
        recognizer = sr.Recognizer()
        with sr.AudioFile("temp_recording.wav") as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio, language="ar")
            return text
    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª: {e}")
        return ""


def main():
    st.title("ğŸ”¬ Ù†Ø¸Ø§Ù… ØªØ´Ø®ÙŠØµ Ø·Ø¨ÙŠ Ø°ÙƒÙŠ")

    knowledge_base = load_knowledge_base()
    if not knowledge_base:
        return

    semantic_network = build_semantic_network(knowledge_base)

    image = Image.open("images (2).jpg")
    st.image(image, use_container_width=True)

    # Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ ÙŠØ¯ÙˆÙŠÙ‹Ø§
    input_text = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶:")

    if st.button("ØªØ´Ø®ÙŠØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†"):
        input_text = recognize_speech()
        if input_text:
            disease, details = diagnose_disease(input_text, knowledge_base, semantic_network)
            if disease:
                st.success(f"ğŸ¦  Ø§Ù„Ù…Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙ…Ù„: {disease}")
                st.write(f"ğŸ“– Ø§Ù„ÙˆØµÙ: {details.get('Ø§Ù„ÙˆØµÙ', '')}")
                st.write(f"ğŸ’Š Ø§Ù„Ø¹Ù„Ø§Ø¬: {', '.join(details.get('Ø§Ù„Ø¹Ù„Ø§Ø¬', []))}")
            else:
                st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø±Ø¶ Ù…Ø·Ø§Ø¨Ù‚.")

    # Ø²Ø± Ø§Ù„ØªØ´Ø®ÙŠØµ
    if st.button("ØªØ´Ø®ÙŠØµ"):
        if input_text:
            disease, details = diagnose_disease(input_text, knowledge_base, semantic_network)
            if disease:
                st.success(f"ğŸ¦  Ø§Ù„Ù…Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙ…Ù„: {disease}")
                st.write(f"ğŸ“– Ø§Ù„ÙˆØµÙ: {details.get('Ø§Ù„ÙˆØµÙ', '')}")
                st.write(f"ğŸ’Š Ø§Ù„Ø¹Ù„Ø§Ø¬: {', '.join(details.get('Ø§Ù„Ø¹Ù„Ø§Ø¬', []))}")
            else:
                st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø±Ø¶ Ù…Ø·Ø§Ø¨Ù‚.")

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø¶ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ
    reverse_search = st.text_input("ğŸ” Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø¶ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø¹Ø±Ø§Ø¶Ù‡:")

    if st.button("ğŸ”„ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹ÙƒØ³ÙŠ"):
        if reverse_search:
            disease_name = reverse_search.strip()
            if disease_name in knowledge_base:
                details = knowledge_base[disease_name]
                symptoms = details.get("Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶", [])
                st.success(f"âœ… Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù€ {disease_name}:")
                st.write(f"ğŸ“ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶: {', '.join(symptoms)}")
            else:
                st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±Ø¶ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        else:
            st.warning("âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø¶ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡.")

    # Ø²Ø± Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø¨ÙƒØ©
    if st.button("ğŸ“ŠØ¹Ø±Ø¶ Ø§Ù„Ø´Ø¨ÙƒØ©"):
        if input_text:
            visualize_network(input_text, semantic_network)
        else:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø£ÙˆÙ„Ø§Ù‹.")


if __name__ == "__main__":
    main()
